{
    "decoder": {
        "unet_sources": [
            {
                "unet_numbers": [1],
                "default_cond_scale": [1.7],
                "load_model_from": {
                    "load_type": "local",
                    "path": "/home/aiinir/semantic_compression/weights/decoder_latest.pth",
                    "cache_dir": "./models",
                    "filename_override": "new_decoder.pth"
                },
                "load_config_from": {
                    "load_type": "local",
                    "path": "./configs/decoder_config.json",
                    "cache_dir": "./models",
                    "filename_override": "decoder_config.json"
                }
            },
            {
                "unet_numbers": [2],
                "load_model_from": {
                    "load_type": "local",
                    "path": "/home/aiinir/semantic_compression/weights/decoder_2_latest.pth",
                    "cache_dir": "./models",
                    "filename_override": "second_decoder.pth"
                },
                "load_config_from": {
                    "load_type": "url",
                    "path": "https://huggingface.co/Veldrovive/upsamplers/raw/main/working/decoder_config.json",
                    "checksum_file_path":  "https://huggingface.co/Veldrovive/upsamplers/raw/main/working/decoder_config.json",
                    "cache_dir": "./models",
                    "filename_override": "second_decoder_config.json"
                }
            }
        ]
    },
    "prior": {
        "load_model_from": {
            "load_type": "local",
            "path": "/home/aiinir/semantic_compression/weights/prior_best.pth",
            "cache_dir": "./models",
            "filename_override": "prior.pth"
        },
        "load_config_from": {
            "load_type": "url",
            "path": "https://huggingface.co/laion/DALLE2-PyTorch/raw/main/prior/prior_config.json",
            "checksum_file_path": "https://huggingface.co/laion/DALLE2-PyTorch/raw/main/prior/prior_config.json",
            "cache_dir": "./models"
        }
    },
    "clip": {
        "make": "openai",
        "model": "ViT-L/14"
    },

    "devices": "cuda:0",
    "strict_loading": false
}
